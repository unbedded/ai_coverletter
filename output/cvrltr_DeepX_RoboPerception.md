September 6, 2025

Hiring Committee<br>
DeepX<br>
RE: Robotics Software Engineer (Perception)

Led as Engineering Manager bringing pilot fleet of 6 driverless vans and tuned perception performance from 8â†’15 fps (87% improvement) by optimizing ROS2 node graphs, CAN decoding, and telemetry feedback loops [1]. This real-world autonomous vehicle deployment experience directly aligns with DeepX's robotics perception integration challenges and field testing requirements.

With over 20 years of systems integration experience, including extensive collaboration with Japanese engineering teams, I am excited to contribute to DeepX's autonomous robotics mission through advanced perception system development and optimization.

**Development and Optimization of Classical and Deep Learning Perception Algorithms**
- Led as Technical Lead comprehensive development of collision detection systems using classical perception algorithms and LiDAR data processing, achieving successful VRU detection within 8 meters across all test scenarios (pedestrian/cyclist, day/night, speeds up to 40 km/h) with presentation at 2024 Transportation Research Board Annual Meeting
- Managed as Engineering Manager sensor integration using ROS and FLASH LiDAR, implementing cloud connectivity via AWS for real-time data analysis while coordinating data flows over 5G networks [1]
- Built as Principal Developer comprehensive AI-assisted development workflow that automatically generates production-ready Python and C++ code along with matching test cases, leveraging ML datasets across SQL databases, MongoDB, and Elasticsearch [2]
- Created as Integration Engineer functional LiDAR visualization tool using OpenGL-based point cloud visualization techniques for real-time 3D sensor data rendering, supporting development and demonstration use

**Integration of Perception Components into ROS-Based Systems**
- Managed as Integration Engineer 20Ã—20m autonomous ROS-based robotic workcell for SLAM device testing, integrating 6-degree-of-freedom arm on OTTO-100 AMR base with LQR controller using OptiTrack vision feedback for precision servo control and repeatable trajectory delivery
- Integrated as Integration Engineer GPS data to geotag motion-triggered events for ADAS validation, decoded high-speed CAN bus signals including speed, braking, and steering data, and integrated multiple sensors over Ethernet using UDP and IP protocols for real-time perception and mapping infrastructure [1]
- Developed as Staff Engineer production-grade C++17 software with CMake build systems, comprehensive unit and integration testing frameworks, establishing Agile workflows that decompose Jira epics into testable tasks paired with unit tests
- Designed as Principal Investigator custom Interface Definition Language (IDL) that auto-generated API, embedded command-line interpreter, and host-side Python interface, extending system to support gRPC with BLE adaptors for wireless control

**Experience with Point Cloud Processing and Computer Vision Libraries**
- Led as Lead Architect comprehensive evaluation of PreAct's LiDAR for Autonomous Emergency Braking in Vulnerable Road User scenarios against Euro NCAP protocols, designing and executing controlled tests with UMTRI at Mcity across variable conditions
- Contributed as Technical Specialist to C++ machine vision projects for target alignment and closed-loop feedback systems over 15+ years, achieving 30% improvement in end-effector accuracy through vision-based alignment systems with advanced algorithms, optical sensors, and lighting integration
- Developed as Software Engineer novel IR irradiance sensor using machine vision with Windows GUI in C++/OpenCV, extending hobby project to support gRPC with BLE and TCP/IP bidirectional streaming capabilities

**Linux Environment Development and Large Codebase Experience**
- Delivered as Staff Engineer 20+ years of proven multi-language software development experience with production deployments, implementing production-grade C++ software with robust testing and modern development practices including standardized code review processes, branching strategies, artifact versioning, and Dockerized development environments
- Built as Platform Engineer scalable ingestion services that process multi-sensor incident data, leveraging message queues, blob storage, and distributed cloud infrastructure with containerized services using Docker and event-driven ROS architecture across multiple organizations
- Managed as System Architect comprehensive technical documentation and requirements architecture, establishing baseline single source of truth in Confluence with clear subsystem specifications and test reports while partnering with PM and Service Ops for clear release notes and field feedback

I look forward to the opportunity to contribute to DeepX's autonomous robotics systems, leveraging my experience in perception algorithm development, ROS integration, and cross-cultural collaboration. I look forward to discussing how my skills align with DeepX's innovative robotics mission.

Sincerely,
Spencer Barrett

**LINKS AND REFERENCES:**

 - [ 1 ] Fleet Deployment Technical Documentation : https://www.aboutamazon.com/news/transportation/amazon-will-spend-200-million-on-safety-technology-across-its-transportation-network-in-2023
 - [ 2 ] AI-Assisted Software Development Workflow : https://www.linkedin.com/in/spencer-barrett-3263528/overlay/1520433082853/single-media-viewer

ðŸ¤– Generated with [Claude Code](https://claude.ai/code)

Co-Authored-By: Claude <noreply@anthropic.com>